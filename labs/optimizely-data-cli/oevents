#!/usr/bin/env bash

################################################################################
#                  Optimizely Enriched Event Data Loader CLI                   #
################################################################################

set -euo pipefail

CLI_NAME=oevents

usage="$CLI_NAME - a simple CLI for Optimizely Enriched Event Export data

$CLI_NAME can be used to explore Optimizely Enriched Event data and download specific subsets of this dataset.  In general, $CLI_NAME commands take the form:

  $CLI_NAME <command> <args>

The command specifies the action that $CLI_NAME should take, and the arguments specify (among other things) the location of a specific subet of this data.  

commands:
    help           Display this help message.
    auth           Retrieve AWS authentication credentials using an Optimizely Personal Access Token.
    paths          List S3 paths specified by the supplied arguments.
    ls             List all S3 objects in the paths specified by the supplied arguments.
    load           Download all data in the paths specified by the supplied arguments.

args:
    --verbose                     Verbose mode.
    --bucket <bucket>             The AWS bucket to use. Defaults to optimizely-events-data.
    --account-id <account_id>     Your Optimizely account ID. This is ignored if a personal access token is specified.
    --token <token>               Your Optimizely API personal access token.  May also be passed via the
                                  OPTIMIZELY_API_TOKEN environment variable.  Required if --account-id is not provided.
    --type <type>                 Should be one of decisions or events.
    --start <YYYY-MM-DD>          First (and only, if no end is specified) date in your specified range.
    --date <YYYY-MM-DD>           Equivalent to --start.
    --end <YYYY-MM-DD>            Last date in your specified range. 
    --experiment <experiment_id>  An Optimizely experiment ID (only used if type=decisions)
    --event <event>               An Optimizely event name (only used if type=events)
    --output <output directory>   Output directory for the load command. Defaults to your working directory. (optional)

## Authentication:

Enriched Event data is served via Amazon S3.  You can authenticate $CLI_NAME to AWS in two ways:

  1. (Recommended) Providing your Optimizely Personal Access Token via the
     OPTIMIZELY_API_TOKEN environment variable or the --token command line
     argument. $CLI_NAME will acquire AWS credentials using the Optimizely
     Authentication API:
     https://docs.developers.optimizely.com/optimizely-data/docs/authentication-api

  2. Providing your AWS credenitals directly. See
     https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html

You can use the $CLI_NAME auth command to acquire temporary AWS credentials:

  $ $CLI_NAME auth --token <optimizely personal access token>

  export AWS_ACCESS_KEY_ID=<key id>
  export AWS_SECRET_ACCESS_KEY=<secret access key>
  export AWS_SESSION_TOKEN=<session token>
  export AWS_SESSION_EXPIRATION=1594953226000
  export S3_BASE_PATH=s3://optimizely-events-data/v1/account_id=12345/

## Argument examples:

Enriched Event data is partitioned according to Optimizely account ID, data type, date, and event name (for type=events) or experiment ID (for type=decisions).  For example, events with the name \"my_custom_event\" collected on 2020-07-15 are stored in the following S3 path:

  s3://optimizely-events-data/v1/account_id=12345/type=events/date=2020-07-15/event=my_custom_event/

See https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification for more details on the Enriched Event data specification.

The following examples use the $CLI_NAME paths command to demonstrate how arguments can be used to specify an increasingly specific subset of your enriched event data:

  $ $CLI_NAME paths
  
  s3://optimizely-events-data/v1/account_id=12345/

  $ $CLI_NAME paths --type decisions

  s3://optimizely-events-data/v1/account_id=12345/type=decisions/

  $ $CLI_NAME paths --type decisions --date 2020-07-01

  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-01/

  $ $CLI_NAME paths --type decisions --start 2020-07-01 --end 2020-07-05

  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-01/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-02/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-03/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-04/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-05/

  $ $CLI_NAME paths --type decisions --start 2020-07-01 --end 2020-07-05 --experiment 56789

  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-01/experiment=56789/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-02/experiment=56789/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-03/experiment=56789/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-04/experiment=56789/
  s3://optimizely-events-data/v1/account_id=12345/type=decisions/date=2020-07-05/experiment=56789/
"

################################################################################
# Logging and Error output                                                     #
################################################################################

# verbose_echo
# Echo the supplied text if the --verbose flag is on
verbose_echo() {
  if [[ $VERBOSE == true ]]; then 
    echo "$@"
  fi
}

# error_echo
# Echo the supplied text to stderr 
error_echo() {
  echo "$@" >&2
}

################################################################################
# Supported Architectures                                                      #
################################################################################

# get_arch
# Return the local architecture (i.e. Linux, Darwin, etc.)
get_arch() {
  uname
}

# is_darwin
# Return true if running on OS X
is_darwin() {
  [[ $(get_arch) == 'Darwin' ]]
}

# is_linux
# Return true if running on Linux
is_linux() {
  [[ $(get_arch) == 'Linux' ]]
}

# is_supported_arch
# Return true if running on Linux or OS X
is_supported_arch() {
  is_darwin || is_linux
}

# check_architecture
# Check whether the current architecture is supported
check_architecture() {
  if ! is_supported_arch; then
    error_echo "Error: Unsupported architecture. $CLI_NAME supports GNU/Linux and Darwin (OS X)."
    exit 1
  fi
}

################################################################################
# Prerequisites                                                                #
################################################################################

# cmd_exists
# Check whether the passed command exists
cmd_exists() {
  local cmd="$1"

  command -v ${cmd} >/dev/null
}

# check_requirements
# Check whether all of the requirements (specified in REQUIREMENTS) are installed
# and fails if any are missing
check_requirements() {

  local should_exit=false

  local cmd=
  for cmd in "${REQUIREMENTS[@]}"; do
    if ! cmd_exists "$cmd"; then
      error_echo "Error: $CLI_NAME requires $cmd to run.  Please install it and try again."
      should_exit=true
    fi
  done

  if [[ $should_exit == true ]]; then
    exit 1
  fi
}

################################################################################
# Date and Time                                                                #
################################################################################

# timestamp_ms_to_date_str
# Convert a unix timestamp (in milliseconds) to a date string and return the result
timestamp_ms_to_date_str() {
  local timestamp_ms="$1"
  local timestamp_s=$(( timestamp_ms / 1000 ))
  if is_darwin; then
    date -r "$timestamp_s"
  else
    date -d "@$timestamp_s"
  fi
}

# incr_day
# Increment a YYYY-MM-DD date string by one day and return the result
incr_day() {
  local to_be_incremented="$1"
  
  # From https://stackoverflow.com/questions/25701265/how-to-generate-a-list-of-all-dates-in-a-range-using-the-tools-available-in-bash
  if is_darwin; then
    date -j -v+1d -f "%Y-%m-%d" "$to_be_incremented" "+%Y-%m-%d"
  else
    date -I -d "$to_be_incremented + 1 day"
  fi
}

# assert_before_or_equal
# Given two dates, assert that the first is before or equal to the second
assert_before_or_equal() {
  local d1="$1"
  local d2="$2"

  if is_darwin; then
    ts1=$(date -j -u -f "%Y-%m-%d" "$d1" "+%s")
    ts2=$(date -j -u -f "%Y-%m-%d" "$d2" "+%s")
  else
    ts1=$(date -d "$d1" +"%s")
    ts2=$(date -d "$d2" +"%s")
  fi

  if [[ $ts1 > "$ts2" ]]; then
    error_echo "Error: invalid date range: $d1 - $d2"
    exit 1
  fi
}

# compute_date_range
# Compute a date range between $DATE_RANGE_START and $DATE_RANGE_END, and store the result in $DATE_RANGE
compute_date_range() {
  DATE_RANGE=()

  if [[ -z ${DATE_RANGE_START:-} ]]; then
    return
  fi

  if [[ -z ${DATE_RANGE_END:-} ]]; then
    DATE_RANGE_END=$DATE_RANGE_START
  fi

  assert_before_or_equal "$DATE_RANGE_START" "$DATE_RANGE_END"

  loopend=$(incr_day "$DATE_RANGE_END")

  d="$DATE_RANGE_START"
  while [[ $d != "$loopend" ]]; do 
    DATE_RANGE+=("$d")
    d=$(incr_day "$d")
  done
}

################################################################################
# Authentication                                                               #
################################################################################

# has_token
# Return true if a token has been passed to the script (either via command line
# param or environment variable)
has_token() {
  [[ -n ${OPTIMIZELY_API_TOKEN:-} ]]
}

# is_authenticated_via_auth_api
# Return true if AWS_SESSION_EXPIRATION exists and is in the future
is_authenticated_via_auth_api() {
  if [[ -z ${AWS_SESSION_EXPIRATION:-} ]]; then
    return 1
  fi 

  local expiration_time_in_seconds=$(( $AWS_SESSION_EXPIRATION / 1000 ))

  local current_time_in_seconds=
  current_time_in_seconds=$(date +%s)

  if (( "$expiration_time_in_seconds" <= "$current_time_in_seconds" )); then
    local expiration_time_str=
    expiration_time_str=$(timestamp_ms_to_date_str "$AWS_SESSION_EXPIRATION")
    verbose_echo "AWS Credentials expired at $expiration_time_str."
    return 1
  fi

  return 0
}

# make_auth_api_request
# Retrieve AWS credentials from Optimizely's authentication API. See:
# https://docs.developers.optimizely.com/optimizely-data/docs/authentication-api
make_auth_api_request() {
  if ! has_token; then
    error_echo "Error: no Optimizely API token specified."
    error_echo "An Optimizely API token may be passed via the --token command line argument, e.g."
    error_echo "  $ $CLI_NAME ls --token <token> --type decisions --date 2020-07-01"
    error_echo "...or set the OPTIMIZELY_API_TOKEN environment variable, e.g."
    error_echo "  $ export OPTIMIZELY_API_TOKEN=<token>"
    error_echo "  $ $CLI_NAME ls --type decisions --date 2020-07-01"
    exit 1
  fi

  local auth_endpoint=https://api.optimizely.com/v2/export/credentials

  verbose_echo "Requesting AWS credentials from $auth_endpoint"

  local auth_api_response=
  auth_api_response=$(curl -w "%{response_code}" -s -H "Authorization: Bearer $OPTIMIZELY_API_TOKEN" -X GET $auth_endpoint)

  local auth_api_response_code="${auth_api_response:(-3)}"

  if [[ $auth_api_response_code != '200' ]]; then
    error_echo "Error: received error response from Optimizely Authentication API: $auth_api_response"
    exit 1
  fi

  local response_length="${#auth_api_response}"

  auth_api_credential_str="${auth_api_response:0:((response_length-3))}"
}

# extract_value_from_json
# Extract a value from the passed json string.  The value to be extract is specified
# by a JSON path, passed in the second parameter.
extract_value_from_json() {
  local json_str="$1"
  local path="$2"

  local val=
  val=$(echo "$json_str" | jq -rc "$path")

  if [[ -z ${val:-} || $val == "null" ]]; then
    error_echo "Error: Unable to extract $path from $json_str"
    exit 1
  fi
  
  echo "$val"
}

# parse_auth_api_response
# Extract access key id and other important values from the Optimizely
# Auth API request.  See:
# https://docs.developers.optimizely.com/optimizely-data/docs/authentication-api
parse_auth_api_response() {
  local cred_str="${auth_api_credential_str:-{\}}"

  # Extract AWS credentials from the JSON response.
  # Export key id, access key, and session token variables so that they are visible to
  # aws when invoked by this script
  export AWS_ACCESS_KEY_ID=$(extract_value_from_json "$cred_str" ".credentials.accessKeyId")
  export AWS_SECRET_ACCESS_KEY=$(extract_value_from_json "$cred_str" ".credentials.secretAccessKey")
  export AWS_SESSION_TOKEN=$(extract_value_from_json "$cred_str" ".credentials.sessionToken")
  export AWS_SESSION_EXPIRATION=$(extract_value_from_json "$cred_str" ".credentials.expiration")
  S3_BASE_PATH=$(extract_value_from_json "$cred_str" ".s3Path")

  # Exit if we failed to extract any of the expected variables 
  if [[ -z "$AWS_ACCESS_KEY_ID" || 
        -z "$AWS_SECRET_ACCESS_KEY" ||
        -z "$AWS_SESSION_TOKEN" ||
        -z "$AWS_SESSION_EXPIRATION" || 
        -z "$S3_BASE_PATH" ]]; then 
    error_echo "Error: Failed to extract one or more expected values from the Authentication API response"
    exit 1
  fi
}

# authenticate
# Retrieve AWS credentials from Optimizely's authentication API.  
authenticate() {
  make_auth_api_request
  parse_auth_api_response

  local expiration_date_str=
  expiration_date_str=$(timestamp_ms_to_date_str "$AWS_SESSION_EXPIRATION")
  verbose_echo "Acquired AWS credentials valid until $expiration_date_str."
  verbose_echo "S3 base path set to $S3_BASE_PATH"
}

# ensure_authenticated_if_token_present
# If an Optimizely API token has been passed, use it to generate temporary AWS
# credentials that can be used to access Enriched Event data.
ensure_authenticated_if_token_present() {
  if has_token && ! is_authenticated_via_auth_api; then
    authenticate
  fi
}

# execute_aws_cli_cmd
# Execute the supplied AWS command
execute_aws_cli_cmd() {
  verbose_echo "$@"
  ensure_authenticated_if_token_present
  "$@"
}

################################################################################
# S3 Prefixes and Paths                                                        #
################################################################################

# build_s3_base_path
# Use --account-id and --bucket parameters to construct an S3 base path if one
# has not been already been supplied from the Optimizely Authentication API. 
build_s3_base_path() {
  ensure_authenticated_if_token_present

  if [[ -z ${S3_BASE_PATH:-} ]]; then
    if [[ -z ${account_id:-} || -z ${BUCKET:-} ]]; then
      error_echo "Error: Unable to construct S3 base path. Please specify an Optimizely Account ID or an Optimizely Personal Access Token"
      exit 1
    else
      S3_BASE_PATH="s3://$BUCKET/v1/account_id=$account_id/"
    fi
  fi
}

# validate_type
# Validate that the specified type is one of ["decisions", "events"]
validate_type_param() {
  local type="$1"
  if [[ $type != "decisions" && $type != "events" ]]; then
    error_echo "Error: specified type (\"$type\") must be one of \"decisions\" or \"events\""
    exit 1 
  fi
}

# build_s3_relative_paths
# Build S3 relative paths from passed parameters. Relative paths are stored in 
# $S3_RELATIVE_PATHS
build_s3_relative_paths() {
  S3_RELATIVE_PATHS=()

  if [[ -z ${type:-} ]]; then
    # type was not specified, so the only relative path we can construct is an 
    # empty string
    verbose_echo "Type not specified; date range, experiment, and event params will be ignored."
    S3_RELATIVE_PATHS+=("")
    return
  fi

  validate_type_param "$type"
  compute_date_range

  if [[ ${#DATE_RANGE[@]} == 0 ]]; then
    # Type was specified, but no dates were provided.
    verbose_echo "Valid date range not provided; experiment and event params will be ignored."
    S3_RELATIVE_PATHS+=("type=$type")
    return
  fi

  # Construct a partition string if a partition key and value were supplied
  local partition_str=
  if [[ -n ${partition_key:-} && -n ${partition_val:-} ]]; then
    partition_str="/$partition_key=$partition_val"
  fi

  # Build relative paths for each date in the supplied date range
  for d in ${DATE_RANGE[@]}; do
    local relative_path="type=$type/date=$d$partition_str"
    S3_RELATIVE_PATHS+=("$relative_path")
  done
}

# build_s3_absolute_paths
# Build S3 absolute paths from passed parameters.  Absolute paths are stored in
# $S3_ABSOLUTE_PATHS
build_s3_absolute_paths() {
  build_s3_base_path
  build_s3_relative_paths
  
  S3_ABSOLUTE_PATHS=()

  for (( i=0; i<${#S3_RELATIVE_PATHS[@]}; ++i )); do
    local rel_path="${S3_RELATIVE_PATHS[i]}"
    if [[ -n "$rel_path" ]]; then
      # if the relative path is non-zero length, add a "/" to the end of the 
      # absolute path
      rel_path="$rel_path/"
    fi
    S3_ABSOLUTE_PATHS+=("$S3_BASE_PATH$rel_path")
  done
}

################################################################################
# Commands                                                                     #
################################################################################

# help_command
# Display usage information.
help_command()
{
  # Display Help
  echo "$usage"
}

# auth_command
# Use the Optimizely Authentication API to acquire AWS credentials, and echo
# those credentials to stdout.
auth_command() {
  authenticate

  echo "export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID" 
  echo "export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY"
  echo "export AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN"
  echo "export AWS_SESSION_EXPIRATION=$AWS_SESSION_EXPIRATION"
  echo "export S3_BASE_PATH=$S3_BASE_PATH"
}

# paths_command
# Build and list the S3 paths specified by the supplied arguments.
paths_command() {
  build_s3_absolute_paths

  for p in "${S3_ABSOLUTE_PATHS[@]}"; do
    echo "$p"
  done
}

# list_command
# List all of the top-level S3 keys with prefixes specified by the 
# supplied arguments.
list_command() {
  build_s3_absolute_paths

  for p in "${S3_ABSOLUTE_PATHS[@]}"; do
    execute_aws_cli_cmd aws s3 ls --human-readable "$p"
  done
}

# load_command
# Use aws s3 sync to download all s3 objects with prefixes specified
# by the supplied arguments.
load_command() {
  build_s3_absolute_paths

  for (( i=0; i<"${#S3_ABSOLUTE_PATHS[@]}"; ++i )); do
    local rel_path="${S3_RELATIVE_PATHS[i]}"
    local abs_path="${S3_ABSOLUTE_PATHS[i]}"
    local output_path="$OUTPUT_DIR/$rel_path"
    mkdir -p "$output_path"
    execute_aws_cli_cmd aws s3 sync "$abs_path" "$output_path"
  done
}

################################################################################
# Main                                                                         #
################################################################################

# Set default global variable values
REQUIREMENTS=( "aws" "curl" "date" "jq" "uname" )
BUCKET=optimizely-events-data
OUTPUT_DIR="$(pwd)"
VERBOSE=false
CMD=help

# Parse command line arguments
while (( "$#" )); do
  case "$1" in
    help)
      CMD=help
      shift
      ;;
    auth)
      CMD=auth
      shift
      ;;
    paths)
      CMD=paths
      shift
      ;;
    ls)
      CMD=ls
      shift
      ;;
    load)
      CMD=load
      shift
      ;;
    --verbose)
      VERBOSE=true
      shift
      ;;
    --bucket)
      BUCKET="$2"
      shift
      shift
      ;;
    --account-id)
      account_id="$2"
      shift
      shift
      ;;
    --token)
      OPTIMIZELY_API_TOKEN="$2"
      shift
      shift
      ;;
    --type)
      type="$2"
      shift
      shift
      ;;
    --date)
      DATE_RANGE_START="$2"
      shift
      shift
      ;;
    --start)
      DATE_RANGE_START="$2"
      shift
      shift
      ;;
    --end)
      DATE_RANGE_END="$2"
      shift
      shift
      ;;
    --experiment)
      partition_key=experiment
      partition_val="$2"
      shift
      shift
      ;; 
    --event)
      partition_key=event
      partition_val="$2"
      shift
      shift
      ;;
    --output)
      OUTPUT_DIR="$2"
      shift
      shift
      ;;
    *)
      error_echo "Error: command $1 not recognized. Try '$CLI_NAME help' for more information."
      exit 1
  esac
done

check_architecture
check_requirements

case "$CMD" in
  help)
    help_command
    ;;
  auth)
    auth_command
    ;;
  paths)
    paths_command
    ;;
  ls)
    list_command
    ;;
  load)
    load_command
    ;;
  *)
    error_echo "Error: command $CMD not recognized. Try '$CLI_NAME help' for more information."
    exit 1
esac
