{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with Enriched Events data using Spark SQL\n",
        "\n",
        "In this Lab we'll learn how to work with [Enriched Event data](https://docs.developers.optimizely.com/web/docs/enriched-events-export) using [PySpark](http://spark.apache.org/docs/latest/api/python/index.html) and [Spark SQL](http://spark.apache.org/sql/).\n",
        "\n",
        "This lab contains a set of simple, useful queries for working with this dataset.  These queries can help you answer questions like\n",
        "- How many visitors were tested in my experiment?\n",
        "- How many \"unique conversions\" of an event were attributed to this variation?\n",
        "- What is the total revenue attributed to this variation?\n",
        "\n",
        "This Lab covers some of the basics of working with event-level experiment data. There are many more useful questions may want to answer with experiment data.  Future tutorials will go deeper on the topic.\n",
        "\n",
        "This guide borrows some initialization code from the [Spark SQL getting started guide](https://spark.apache.org/docs/latest/sql-getting-started.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to run this notebook\n",
        "\n",
        "This lab lives in the [Optimizely Labs](https://github.com/optimizely/labs) repository.  Each lab contains a `README.md` file with instructions for running notebooks and any other executable code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL\") \\\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
        "    .config(\"spark.sql.repl.eagerEval.truncate\", 100) \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Enriched Event data\n",
        "\n",
        "The `OPTIMIZELY_DATA_DIR` environment variable may be used to specify the local directory where Enriched Event data is stored.  If, for example, you've [downloaded Enriched Event data](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-getting-started) and saved it in `optimizely_data` in your home directory, you can load that data in this notebook by executing the following command before launching Jupyter Lab:\n",
        "\n",
        "```\n",
        "$ export OPTIMIZELY_DATA_DIR=~/optimizely_data\n",
        "```\n",
        "\n",
        "If `OPTIMIZELY_DATA_DIR` is not set, data will be loaded from `./data` in your working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_data_dir = os.environ.get(\"OPTIMIZELY_DATA_DIR\", \"./example_data\")\n",
        "\n",
        "def read_data(path, view_name):\n",
        "    \"\"\"Read parquet data from the supplied path and create a corresponding temporary view with Spark.\"\"\"\n",
        "    spark.read.parquet(path).createOrReplaceTempView(view_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enriched Event data is partitioned into two distinct datasets: [decisions](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#decisions-2) and [conversions](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#conversions-2).\n",
        "\n",
        "We'll load decision data from the `type=decisions` directory in the base data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decisions_dir = os.path.join(base_data_dir, \"type=decisions\")\n",
        "read_data(decisions_dir, \"decisions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll load conversion data from the `type=events` directory in the base data directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "events_dir = os.path.join(base_data_dir, \"type=events\")\n",
        "read_data(events_dir, \"events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Querying our data\n",
        "\n",
        "Now that we've loaded our data, we can query it using the `sql()` function.  Here's an example on our `decisions` view:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM decisions\n",
        "    LIMIT 1\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's an example on our `events` view:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM events\n",
        "    LIMIT 1\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Useful queries\n",
        "\n",
        "Next we'll cover some simple, useful queries for working with Optimizely's Enriched Event data. \n",
        "\n",
        "These queries are parameterized with the following values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The analysis window for your queries.  Change these values if you wish to restrict the event data included in your\n",
        "# queries\n",
        "start = \"2010-01-01 00:00:00\"\n",
        "end = \"2050-12-31 23:59:59\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting the unique visitors in an Optimizely Web experiment \n",
        "\n",
        "[Optimizely Web]: https://www.optimizely.com/platform/experimentation/\n",
        "[Optimizely Full Stack]: https://docs.developers.optimizely.com/full-stack/docs\n",
        "\n",
        "[Optimizely Web] and [Optimizely Full Stack] experiment results pages count unique visitors in slightly different ways.  \n",
        "\n",
        "Given a particular analysis time window (between `start` and `end`) [Optimizely Web] attributes all visitors who were exposed to a variation at any time between when the experiment started and `end` and sent _any_ event (decision or conversion) to Optimizely between `start` and `end`.\n",
        "\n",
        "The following query captures that attribution logic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the unique visitors from all events (Optimizely Web)\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT \n",
        "        experiment_id,\n",
        "        variation_id,\n",
        "        COUNT (distinct visitor_id) as `Unique visitors (Optimizely Web)`\n",
        "    FROM (\n",
        "        SELECT\n",
        "            exp.experiment_id as experiment_id,\n",
        "            exp.variation_id as variation_id,\n",
        "            visitor_id\n",
        "        FROM events\n",
        "        LATERAL VIEW explode(experiments) t AS exp\n",
        "        WHERE timestamp between '{start}' AND '{end}'\n",
        "        UNION\n",
        "        SELECT\n",
        "            experiment_id,\n",
        "            variation_id,\n",
        "            visitor_id\n",
        "        FROM decisions\n",
        "        WHERE\n",
        "            timestamp between '{start}' AND '{end}'\n",
        "            AND is_holdback = false\n",
        "        )\n",
        "    GROUP BY\n",
        "        experiment_id,\n",
        "        variation_id\n",
        "    ORDER BY\n",
        "        experiment_id ASC,\n",
        "        variation_id ASC\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**A note on `timestamp` vs `process_timestamp`:** If you're working on re-computing the numbers you see on your [experiment results page](https://help.optimizely.com/Analyze_Results/The_Experiment_Results_page_for_Optimizely_X), it's important to understand the difference between the `timestamp` and `process_timestamp` fields in your Enriched Events data.\n",
        "\n",
        "- `timestamp` contains the time set by the _client_, e.g. the Optimizely Full Stack SDK\n",
        "- `process_timestamp` contains the approximate time that the event payload was received by Optimizely\n",
        "\n",
        "The difference is important because Enriched Event data is partitioned by `process_timestamp`, but Optimizely results are computed using `timestamp`.  This allows clients to send events retroactively, but also means that depending on your implementation you may need to load a wider range of data in order to ensure that you've captured all of the events with a `timestamp` in your desired analysis range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting the unique visitors in an Optimizely Full Stack experiment \n",
        "\n",
        "[Optimizely Web]: https://www.optimizely.com/platform/experimentation/\n",
        "[Optimizely Full Stack]: https://docs.developers.optimizely.com/full-stack/docs\n",
        "\n",
        "The [Full Stack][Optimizely Full Stack] attribution model is a little simpler:\n",
        "\n",
        "Given a particular analysis time window (between `start` and `end`) [Full Stack][Optimizely Full Stack] attributes all visitors who were exposed to a variation at any time between `start` and `end`.  We measure this by counting the unique `visitor_id`s in the decisions dataset for that experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the unique visitors from decisions (Optimizely Full Stack)\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        experiment_id,\n",
        "        variation_id,\n",
        "        COUNT(distinct visitor_id) as `Unique visitors (Full Stack)`\n",
        "    FROM decisions\n",
        "    WHERE\n",
        "        timestamp between '{start}' AND '{end}'\n",
        "        AND is_holdback = false\n",
        "    GROUP BY\n",
        "        experiment_id,\n",
        "        variation_id\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting conversions in an Optimizely Web experiment\n",
        "\n",
        "[Optimizely Web]: https://www.optimizely.com/platform/experimentation/\n",
        "[Optimizely Full Stack]: https://docs.developers.optimizely.com/full-stack/docs\n",
        "\n",
        "When it comes to counting conversions, [Optimizely Full Stack] and [Optimizely Web] do things a little differently.\n",
        "\n",
        "Given a particular analysis time window (between `start` and `end`) [Optimizely Web] will attribute an event to a particular variation if the visitor who triggered that event was exposed to the variation at any time prior to that event, _even if it was before the beginning of the analysis time window._\n",
        "\n",
        "Optimizely event data is enriched with a an attribution column, `experiments`, that lists all of the experiments and variations to which an event has been attributed. Since Optimizely Web does not require that a corresponding decision take place during the analysis window, we can use a simple query to count the number of attributed conversions during our analysis window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the unique conversions of a particular event attributed to an experiment\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT \n",
        "        exp.experiment_id as experiment_id,\n",
        "        exp.variation_id as variation_id,\n",
        "        event_name,\n",
        "        COUNT(1) as `Conversion count (Optimizely Web)`\n",
        "    FROM events\n",
        "    LATERAL VIEW explode(experiments) t AS exp\n",
        "    WHERE \n",
        "        timestamp between '{start}' AND '{end}'\n",
        "    GROUP BY\n",
        "        experiment_id, variation_id, event_name\n",
        "    ORDER BY\n",
        "        experiment_id DESC,\n",
        "        variation_id DESC,\n",
        "        event_name ASC\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting conversions in an Optimizely Full Stack experiment\n",
        "\n",
        "[Optimizely Web]: https://www.optimizely.com/platform/experimentation/\n",
        "[Optimizely Full Stack]: https://docs.developers.optimizely.com/full-stack/docs\n",
        "\n",
        "Given a particular analysis time window (between `start` and `end`) [Optimizely Full Stack] will attribute an event to a particular variation if the visitor who triggered that event was exposed to the variation prior to that event and _during the analysis window._\n",
        "\n",
        "Since Optimizely Full Stack requires that a corresponding decision take place during the analysis window, the query required to attribute events to experiments and variation is more complex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "    SELECT \n",
        "        experiment_id,\n",
        "        variation_id,\n",
        "        event_name,\n",
        "        COUNT (1) as `Conversion count (Optimizely Full Stack)`\n",
        "    FROM (\n",
        "         SELECT \n",
        "             d.experiment_id,\n",
        "             d.variation_id,\n",
        "             e.event_name,\n",
        "             e.visitor_id\n",
        "         FROM events e\n",
        "         INNER JOIN \n",
        "         (\n",
        "            SELECT \n",
        "                experiment_id,\n",
        "                variation_id,\n",
        "                visitor_id,\n",
        "                MIN(timestamp) as decision_timestamp\n",
        "            FROM decisions\n",
        "            WHERE \n",
        "                timestamp between '{start}' AND '{end}'\n",
        "                AND is_holdback = false\n",
        "            GROUP BY\n",
        "                experiment_id,\n",
        "                variation_id,\n",
        "                visitor_id\n",
        "         ) d \n",
        "         ON e.visitor_id = d.visitor_id\n",
        "         WHERE\n",
        "             e.timestamp  between '{start}' AND '{end}'\n",
        "             AND e.timestamp >= d.decision_timestamp\n",
        "    )\n",
        "    GROUP BY\n",
        "         experiment_id,\n",
        "         variation_id,\n",
        "         event_name\n",
        "    ORDER BY\n",
        "         experiment_id DESC,\n",
        "         variation_id ASC\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "optimizelylabs",
      "language": "python",
      "display_name": "Python 3 (Optimizely Labs)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
